# -*- coding: utf-8 -*-
"""Logo_Contest_AY2020_2021.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a3wsAsj6WLdhLKy7z_Ljw0XI9J_huzo0

# **Visual Logo Recognition Contest**
VISION AND COGNITIVE SERVICES A.Y. 2020/2021

The aim of the contest is to retrieve the most similar images representing logos of famous companies from a database set containing 110 images. We will consider 4 query images and use the SIFT algorithm. The performance of the model will be evaluated using precision, recall and average precision metrics for each for the query logos.
You can modify the baseline (parameters, feature matching technique, ...) and send your results.

- [Send your results](https://forms.gle/GTrXtqcTpFC6g14P6)
- [Visualize rank](https://docs.google.com/spreadsheets/d/e/2PACX-1vRFd6yf-OHsrtlONu6i_0Yu2FRBItV8qSzxi_PSp_MtuGaxgM-_0fzSyvyNjKC01IBI3Uyft32pF4hT/pubhtml)
"""

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip uninstall opencv-python -y
# # Change OpenCV version since patented and experimental algorithms
# # are contained in opencv_contrib package
# !pip install opencv-contrib-python --force-reinstall
#

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !unzip query.zip
# !unzip database.zip

# Commented out IPython magic to ensure Python compatibility.
import os
import cv2
import numpy as np
import matplotlib.pyplot as plt

# %matplotlib inline

# List of query/database images
query_images = []
db_images = []
logo_names = []

# Resize images
img_size = (400, 400)

# Read query images
# Order by name

query_dir = sorted(os.listdir('query/'))
for idx, img_name in enumerate(query_dir):
    # Read image
    img = cv2.imread(os.path.join('query/', img_name))
    # Resize image
    img = cv2.resize(img, dsize=img_size)
    # Save image
    query_images.append(img)
    # Save logo names (remove "_logo.txt" and capitalize)
    logo_names.append(os.path.splitext(img_name)[0][:-5].capitalize())
    # print("Image '" + img_name + "' loaded.")
print("Query images loaded!")

# Read db images
# Order by number
db_dir = sorted(os.listdir('database/'), key=lambda x: int(x.split('.')[0]))
for idx, img_name in enumerate(db_dir):
    # Read image
    img = cv2.imread(os.path.join('database/', img_name))
    # Resize image
    img = cv2.resize(img, dsize=img_size)
    # Save image
    db_images.append(img)
    # print("Image '" + img_name + "' loaded.")
print("Database images loaded!")

# Plot query images
fig = plt.figure(figsize=(12, 12))
for i in range(len(query_images)):
    _ = plt.subplot(1, len(query_images), i + 1), plt.title("Query image n. " + str(i))
    plt.imshow(cv2.cvtColor(query_images[i], cv2.COLOR_BGR2RGB)), plt.axis('off')

# Plot database images
fig = plt.figure(figsize=(12, 80))
for i in range(len(db_images)):
    _ = plt.subplot(len(db_images) / 5, 5, i + 1), plt.title("DB image n. " + str(i))
    plt.imshow(cv2.cvtColor(db_images[i], cv2.COLOR_BGR2RGB)), plt.axis('off')

# # Ground-truth arrays per logo
coca_cola_GT = np.zeros(len(db_images))
marlboro_GT = np.zeros(len(db_images))
starbucks_GT = np.zeros(len(db_images))
heineken_GT = np.zeros(len(db_images))

coca_cola_GT[18:25] = 1
marlboro_GT[55:61] = 1
marlboro_GT[100:] = 1
starbucks_GT[70:100] = 1
heineken_GT[25:55] = 1

# Matrix containing ground-truth values for each query image
GT_matrix = np.vstack([coca_cola_GT, heineken_GT, marlboro_GT, starbucks_GT])
print(f"GT matrix shape: {GT_matrix.shape}")

n_coca_cola = int(coca_cola_GT.sum())
n_heineken = int(heineken_GT.sum())
n_marlboro = int(marlboro_GT.sum())
n_starbucks = int(starbucks_GT.sum())
n_others = len(db_images) - (n_coca_cola + n_heineken + n_marlboro + n_starbucks)
print(f"Number of database images (coca_cola): {n_coca_cola}")
print(f"Number of database images (heineken): {n_heineken}")
print(f"Number of database images (marlboro): {n_marlboro}")
print(f"Number of database images (starbucks): {n_starbucks}")
print(f"Number of database images (others): {n_others}")
# print(GT_matrix)


"""SIFT algorithm (default parameters) """

# Define SIFT detector object
# retval	=	cv.xfeatures2d.SIFT_create(	[, nfeatures=150[, nOctaveLayers=4[, contrastThreshold=0.04[, edgeThreshold=10[, sigma=1.6]]]]]	)
# nfeatures=200, nOctaveLayers=4, contrastThreshold=0.04, edgeThreshold=10, sigma=1.6
grid = []
contrast_list = np.linspace(0.02, 0.1, 10)
sigmas = np.linspace(1.5, 2.5, 10)
features = [500, 750, 1000, 1250,  1500, 2000, 2500, 3000]
layers = [10, 15, 20, 25, 30, 35]
edges = [3, 4, 5, 6, 7, 8, 9, 10]
treshes = np.linspace(0.6, 0.9, 10)
for feature in features:
    for layer in layers:
        for edge in edges:
            for sigma in sigmas:
                for contrast in contrast_list:
                    for tresh in treshes:
                        detector = cv2.SIFT_create(nfeatures=feature, nOctaveLayers=layer, contrastThreshold=contrast,
                                                   edgeThreshold=edge,
                                                   sigma=sigma)
                        query_kps = []
                        query_des = []
                        db_kps = []
                        db_des = []
                        for i in range(len(query_images)):
                            kp, des = detector.detectAndCompute(query_images[i], None)
                            query_kps.append(kp)
                            query_des.append(des)
                        for i in range(len(db_images)):
                            kp, des = detector.detectAndCompute(db_images[i], None)
                            db_kps.append(kp)
                            db_des.append(des)
                        bf = cv2.BFMatcher_create(cv2.NORM_L2)
                        num_matches = np.zeros((len(query_images), len(db_images)))
                        ratio_thresh = tresh
                        logo_matches = []
                        for q in range(len(query_images)):
                            q_matches = []
                            for db in range(len(db_images)):
                                matches = bf.knnMatch(query_des[q], db_des[db], k=2)
                                n_matches = 0
                                sel_matches = []
                                for m, n in matches:
                                    if m.distance < ratio_thresh * n.distance:
                                        n_matches += 1
                                        sel_matches.append(m)
                                num_matches[q, db] = n_matches
                                q_matches.append(sel_matches)
                            logo_matches.append(q_matches)
                        AP_all = np.zeros(len(query_images))
                        for i in range(len(query_images)):
                            idx = np.argsort(-num_matches[i])
                            TP = GT_matrix[i, idx] == 1
                            FP = GT_matrix[i, idx] == 0
                            TP = np.cumsum(TP)
                            FP = np.cumsum(FP)
                            prec = TP / (TP + FP);
                            rec = TP / np.sum(GT_matrix[i]);
                            AP = 0;
                            interp_prec = []
                            for t in np.linspace(0, 1, num=11):
                                p = prec[rec >= t]
                                if p.size == 0:
                                    p = 0
                                else:
                                    p = p.max()
                                interp_prec.append(p)
                                AP = AP + p / 11
                            AP_all[i] = AP
                        for i in range(len(query_images)):
                            print(f"{logo_names[i]} - Average Precision (AP): {AP_all[i]:.3f}")
                            if AP_all[i] > 0.90:
                                grid.append(AP_all[i])
                                grid.append([logo_names[i], tresh, contrast, sigma, edge, layer, feature])
                        print(f"\nmAP: {np.mean(AP_all):.3f}")
                        print('tresh:', tresh, 'contrast:', contrast, 'sigma:', sigma, 'edge:', edge, 'layer:', layer,
                              'feature:', feature)

print(grid)
